# -*- coding: utf-8 -*-
"""DataSpaces.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KsXtlVtav6l5JCkABqcm5yAzP2jHavY-

**Import library**
"""

import pandas as pd
import csv
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.pyplot import *
import warnings

#Ignoriamo i possibili warnings che possiamo avere
warnings.filterwarnings("ignore")

"""**Import dataset**"""

data = pd.read_csv('/content/Indian Liver Patient Dataset (ILPD) 2.csv')    #Lettura del file train

print(data.head())
print(data.columns)
print('entry totali per ilpd: ', len(data)) #Totale entry = 583

data.describe()

"""**Data exploration (1) - clean dataset**"""

print(data.info())
#Notiamo che l'attributo 'Gender' è una stringa che può essere male/female e quindi sostituiamo
#male = 1; female = 0;
mapping = {'Male':1, 'Female':0}        #Creo un dizionario
data = data.replace({'gender':mapping}) #Faccio un replace all'attributo gender

#Vediamo se esistono NaN 
nullValue = data.isnull().sum()
print('I valori nulli sono: ', nullValue)

#Di seguito sostituiamo tutti i NaN con 0
data.fillna({'alkphos':0}, inplace=True)

"""**Pie chart - diagnosi e gender pazienti**"""

target_counts = data['is_patient'].value_counts().values
gender_counts=data['gender'].value_counts().values

fig1, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5))

target_sizes = data.groupby('is_patient').size()
axes[0].pie(x=target_counts, 
            labels=['patient({})'.format(target_sizes[1]), 'not_patient({})'.format(target_sizes[2])],
            autopct='%1.1f%%')
axes[0].set_title('Diagnosi pazienti')

gender_sizes = data.groupby('gender').size()
axes[1].pie(x=gender_counts,
            labels=['male({})'.format(gender_sizes[1]), 'female({})'.format(gender_sizes[0])],
            autopct="%1.1f%%")
axes[1].set_title('Genere pazienti')

fig, ax = subplots()
df = data.groupby('gender').age
df.plot(kind='kde', ax=ax)    #kde = Kernel Density Estimation plot
ax.legend(["0 Female", "1 Male"]);

#Numeri di is_patient =1 e =2 divisi per gender 
sns.countplot(y=data.is_patient, hue=data.gender)

"""**LabelEncoder del genere**"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
data.gender = le.fit_transform(data.gender)
data.head()

data_original = data.copy()

"""**Normalizzazione dei dati**"""

from sklearn.preprocessing import MinMaxScaler

features=['age', 'gender', 'tot_bilirubin', 'direct_bilirubin','tot_proteins', 'albumin', 'ag_ratio','sgpt','sgot','alkphos','is_patient']
mms = MinMaxScaler()
data = mms.fit_transform(data)

data = pd.DataFrame(data=data, columns=features)

data.head()

"""**Plot prima e dopo della normalizzazione**"""

fig, ax = plt.subplots(1,2)
sns.distplot(data_original, ax=ax[0])
ax[0].set_title('Original Data')
sns.distplot(data, ax=ax[1])
ax[1].set_title('Normalized data')

"""**Matrice di correlazione**"""

corr = data.corr()

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=np.bool))

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 10, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.5, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .3})

"""**Correlation Matrix (II Parte)**"""

f, ax = plt.subplots(figsize=(11, 9))
sns.heatmap(corr)

"""**Correlation matrix (III Parte)**"""

corr = data.corr()
corr.style.background_gradient(cmap='coolwarm')

"""**Matrice di correlazione (III Parte) con algoritmo di clustering gerarchico**"""

import scipy.cluster.hierarchy as spc

pdist = spc.distance.pdist(corr)
linkage = spc.linkage(pdist, 'single', 'correlation')
idx = spc.fcluster(linkage, 0.5*pdist.max(), 'distance')
spc.dendrogram(linkage, color_threshold=0)

"""*Esempio della dipendenza tra due grandezze*"""

gen_totbili = sns.FacetGrid(data, col='gender', row='is_patient', margin_titles=True)
gen_totbili.map(plt.scatter, 'direct_bilirubin', 'tot_bilirubin', edgecolor='k')
plt.subplots_adjust(top=1)

"""*Esempio dell'indipendenza tra due grandezze*"""

gen_totbili = sns.FacetGrid(data, col='gender', row='is_patient', margin_titles=True)
gen_totbili.map(plt.scatter, 'sgpt', 'tot_bilirubin', edgecolor='k')
plt.subplots_adjust(top=1)

sns.jointplot("tot_bilirubin", "direct_bilirubin", data=data, kind="reg")

"""**Cancello attributi correlati**"""

data = data.drop(['direct_bilirubin', 'albumin', 'sgpt'], axis=1)

"""**Outlier - box plot (1 parte)**"""

#Qui stampo i boxplot per il caso is_patient=1
f, ax = plt.subplots(figsize=(11, 9))
mask = (data['is_patient']==0)
data1 = data.loc[mask, ['tot_bilirubin', 'alkphos', 'sgot']]
ax = sns.boxplot(data=data1[['tot_bilirubin', 'alkphos', 'sgot']], orient="h")

#Qui stampo i boxplot per il caso is_patient=2
f2, ax2 = plt.subplots(figsize=(11, 9))
mask = (data['is_patient']==1)
data1 = data.loc[mask, ['tot_bilirubin', 'alkphos', 'sgot']]
ax2 = sns.boxplot(data=data1[['tot_bilirubin', 'alkphos', 'sgot']], orient="h")

"""**Outlier - box plot (2 parte)**"""

#Qui stampo i boxplot per il caso is_patient=1
f, ax = plt.subplots(figsize=(11, 9))
mask = (data['is_patient']==0)
data1 = data.loc[mask, ['tot_proteins', 'ag_ratio']]
ax = sns.boxplot(data=data1[['tot_proteins', 'ag_ratio']], orient="h")

#Qui stampo i boxplot per il caso is_patient=2
f2, ax2 = plt.subplots(figsize=(11, 9))
mask = (data['is_patient']==1)
data1 = data.loc[mask, ['tot_proteins', 'ag_ratio']]
ax2 = sns.boxplot(data=data1[['tot_proteins', 'ag_ratio']], orient="h")

"""**Test and split**"""

from sklearn.model_selection import train_test_split
X = data.drop('is_patient', axis=1).values
y = data['is_patient'].values

#Divido il set in train e test
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=0)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

"""**Standardize - StandardScaler()**"""

from sklearn.preprocessing import StandardScaler
import seaborn as sns

col_names = list(data.columns)

# Stampo senza standardizzare

fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))
fig = set(xlim(-15,15))
ax1.set_title('Original Distributions')
sns.kdeplot(data['age'], ax=ax1)
sns.kdeplot(data['tot_bilirubin'], ax=ax1)
sns.kdeplot(data['tot_proteins'], ax=ax1)
sns.kdeplot(data['ag_ratio'], ax=ax1)
sns.kdeplot(data['sgot'], ax=ax1)
sns.kdeplot(data['alkphos'], ax=ax1)

#Adesso standardizzo
ss = StandardScaler()

X_train = ss.fit_transform(X_train)
X_test = ss.transform(X_test)

X=data;

X = ss.fit_transform(X)
X = pd.DataFrame(X, columns=col_names)
fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))
fig = set(xlim(-15,15))
ax1.set_title('After StandardScaler')
sns.kdeplot(X['age'], ax=ax1)
sns.kdeplot(X['tot_bilirubin'], ax=ax1)
sns.kdeplot(X['tot_proteins'], ax=ax1)
sns.kdeplot(X['ag_ratio'], ax=ax1)
sns.kdeplot(X['sgot'], ax=ax1)
sns.kdeplot(X['alkphos'], ax=ax1)

"""**PCA (n_components=None)** per vederne la varianza"""

#Percentuale di varianza rispetto ad ogni componente principale
#rispetto alla varianza comulativa di tutte le componenti
from sklearn.decomposition import PCA

pca = PCA(n_components=None)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
explained_variance = pca.explained_variance_ratio_
print("Explained Variance:\n", explained_variance)

plt.figure(figsize=(12,8))
plt.step(range(0,7), np.cumsum(pca.explained_variance_ratio_), where='mid')
plt.bar(range(0,7), pca.explained_variance_ratio_)
plt.ylabel("Varianza")
plt.xlabel("Componenti principali")

"""**PCA**"""

from sklearn.decomposition import PCA

pca = PCA(n_components=6)
pc_train = pca.fit_transform(X_train)
pc_test = pca.fit_transform(X_test)

"""**K-Fold - LogisticRegression**"""

from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
kfold = StratifiedKFold(n_splits=10, random_state=1)
scores=[]
for k,(train, test) in enumerate(kfold.split(pc_train, y_train)):
  lr.fit(pc_train[train], y_train[train])
  score = lr.score(pc_train[test], y_train[test])
  scores.append(score)
  print("Fold %d: Accuracy=%.4f" % (k,score))

accuracy = np.array(scores).mean()
print("Validation accuracy = %.4f" % accuracy)

'''
Il numero di esempi appartenenti ad una determinata classe in ogni k-fold potrebbe
essere sbilanciata, per questo usiamo la classe StratifiedKFold. Il risultato
nell'esempio in questione non cambia di molto le cose
'''

from sklearn.model_selection import cross_val_score

lr = LogisticRegression()
score = cross_val_score(lr, pc_train, y_train, cv=10)
print(score)
print(score.mean())

lr.fit(pc_train, y_train)

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,precision_recall_fscore_support
from sklearn.metrics import log_loss

y_pred = lr.predict(pc_test)
y_pred_proba = lr.predict(pc_test)

print("Accuracy: " + str(accuracy_score(y_test, y_pred)))
conf_mat = confusion_matrix(y_test, y_pred)
print(conf_mat)
print("Classification Report: \n", classification_report(y_test, y_pred))

"""**Classificazione con diversi modelli predittivi**"""

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

models=[]
models.append(("LR",LogisticRegression()))
models.append(("NB",GaussianNB()))
models.append(("KNN",KNeighborsClassifier(n_neighbors=5)))
models.append(("DT",DecisionTreeClassifier()))
models.append(("SVM",SVC()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('RFC', RandomForestClassifier()))

for name, model in models:
  kfold = KFold(n_splits=10 , random_state=0)
  cv_result = cross_val_score(model, pc_train, y_train, cv=kfold, scoring='accuracy')
  print("{} ha una accuratezza sul train del: {:0.2f}".format(name,cv_result.mean()))

"""**Classificazione - (kNN)**"""

from sklearn.neighbors import KNeighborsClassifier

clf = KNeighborsClassifier(n_neighbors=2)
clf.fit(pc_train, y_train)
y_test_pred = clf.predict(pc_test);
print(accuracy_score(y_test, y_test_pred))
p,r,f1,s = precision_recall_fscore_support(y_test,y_test_pred)
conf_mat = confusion_matrix(y_test, y_test_pred)
print(conf_mat)
print("Classification Report: \n", classification_report(y_test, y_test_pred))

k_values = np.arange(1,9)
#train_accuracy = []
#test_accuracy = []
for i,k in enumerate (k_values):
  knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(pc_train, y_train)
  train_accuracy.append(knn.score(pc_train, y_train))
  test_accuracy.append(knn.score(pc_test, y_test))

plt.title('k-NN: Varying Number of Neighbors')
plt.plot(k_values, test_accuracy, label='Testing Accuracy')
plt.plot(k_values, train_accuracy, label='Training Accuracy')
plt.legend()
plt.xlabel('Number of Neighbors')
plt.ylabel('Accuracy')
plt.show()

"""**Troviamo il miglior classificatore usando GridSearchCV**"""

params_clfs = list()

svm_params=[{'kernel': ['rbf'], 'gamma':[1e-3,1e-4]},
            {'kernel': ['linear'], 'C':[1,10,100,1000]}
]
params_clfs.append((SVC(), svm_params))

lr_params = {'penalty':['l1','l2'], 'C':np.logspace(0,4,10)}
params_clfs.append((LogisticRegression(),lr_params))

clf=DecisionTreeClassifier()
dt_params = {'max_features': ['auto', 'sqrt','log2'],
             'min_samples_split':[2,3,4,5,6,7,8,9,10,11,12,13,14,15],
             'min_samples_leaf':[1],
             'random_state':[12]}
params_clfs.append((DecisionTreeClassifier(), dt_params))

rfc_params = [{'criterion':['gini', 'entropy'],
               'max_depth':[5,6,7,8,9,10,11,12],
               'max_features':[1,2,3],
               'n_estimators': [14,15,16,17,18,19],
               'random_state': [7,8,9,10,11,12,13]}]
params_clfs.append((RandomForestClassifier(), rfc_params))

"""**GridSearchCV per ricerca degli iperparametri (mediante uso di k-Fold)**"""

from sklearn.model_selection import GridSearchCV

for clf,param in params_clfs:
  grid_search = GridSearchCV(clf,param, cv=10)
  grid_search.fit(pc_train, y_train)
  print(80*"*")
  print("{} GridSearchCV:".format(clf.__class__.__name__))
  print("best params:{}".format(grid_search.best_params_))
  test_means = grid_search.cv_results_['mean_test_score']
  print('Risultato medio:{:.2f}'.format(np.mean(test_means)))
  y_pred = grid_search.predict(pc_test)
  print('Milgior parametro:{:.2f}'.format(accuracy_score(y_test,y_pred)))
  print('Confusion Matrix:\n{}'.format(confusion_matrix(y_test,y_pred)))
  print('Classification report:\n{}'.format(classification_report(y_test,y_pred)))
  print(80*'*')

"""**LDA**"""

clf = LinearDiscriminantAnalysis(n_components=None)
clf.fit(pc_train,y_train)
y_pred = clf.predict(pc_test)
print("Accuracy Score: {:.2f}".format(accuracy_score(y_test, y_pred)))
print("Confusione matrix:\n{}".format(confusion_matrix(y_test,y_pred)))
print("Classification report:\n{}".format(classification_report(y_test,y_pred)))

"""**Decision Tree**"""

clf = DecisionTreeClassifier(max_features='auto', min_samples_leaf=1, min_samples_split=5, max_depth=3, random_state=12)
clf.fit(pc_train, y_train)
y_pred = clf.predict(pc_test)
print("Accuracy Score: {:.2f}".format(accuracy_score(y_test, y_pred)))
print("Confusione matrix:\n{}".format(confusion_matrix(y_test,y_pred)))
print("Classification report:\n{}".format(classification_report(y_test,y_pred)))

"""**Plot tree**"""

from sklearn.tree import DecisionTreeClassifier, plot_tree
plt.figure(figsize=(10, 8))
plot_tree(clf, filled=True)
plt.show()

"""**Random Forest Classifier**"""

random_forest = RandomForestClassifier(criterion='gini', max_depth=5, max_features=1, n_estimators=16, random_state=12)
random_forest.fit(pc_train, y_train)
y_pred = random_forest.predict(pc_test)
print("Accuracy Score: {:.2f}".format(accuracy_score(y_test, y_pred)))
print("Confusione matrix:\n{}".format(confusion_matrix(y_test,y_pred)))
print("Classification report:\n{}".format(classification_report(y_test,y_pred)))

random_forest_score = round(random_forest.score(pc_train, y_train) * 100, 2)
random_forest_score_test = round(random_forest.score(pc_test, y_test) * 100, 2)
print('Random Forest Score: \n', random_forest_score)
print('Random Forest Test Score: \n', random_forest_score_test)
print('Accuracy: \n', accuracy_score(y_test,y_pred))
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""**SVC**"""

best_clf = SVC(gamma=0.001, kernel='rbf')
best_clf.fit(pc_train, y_train)
y_pred = best_clf.predict(pc_test)
print("Accuracy Score: {:.2f}".format(accuracy_score(y_test, y_pred)))
print("Confusione matrix:\n{}".format(confusion_matrix(y_test,y_pred)))
print("Classification report:\n{}".format(classification_report(y_test,y_pred)))

"""**LogisticRegression**"""

best_clf = LogisticRegression(C=21, penalty='l2')
best_clf.fit(pc_train, y_train)
y_pred = best_clf.predict(pc_test)
print("Accuracy Score: {:.2f}".format(accuracy_score(y_test, y_pred)))
print("Confusione matrix:\n{}".format(confusion_matrix(y_test,y_pred)))
print("Classification report:\n{}".format(classification_report(y_test,y_pred)))

"""**Learning curve**"""

from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(KNeighborsClassifier(n_neighbors=2),
              pc_train, y_train, cv=10, scoring='accuracy', n_jobs=-1, 
              train_sizes=np.linspace(0.01,1,50), verbose=1)

'''
I parametri ritornati dalla funzione learning_curve sono:
- train_sizes --> numbers of training examples that has been used to generate the learning curve.
  Note that the number of ticks might be less than n_ticks because duplicate entries will be removed.
- train_scores --> scores on training sets
- test_scores --> scores on test set
'''

train_mean = np.mean(train_scores, axis=1)
train_mean

train_std = np.std(train_scores, axis=1)
train_std

test_mean = np.mean(test_scores, axis=1)
test_mean

test_std = np.std(test_scores, axis=1)
test_std

plt.plot(train_sizes, train_mean, label= 'Training Score')
plt.plot(train_sizes, test_mean, label = 'Cross-Validation Score')
plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, color='#DDDDDD')
plt.fill_between(train_sizes, test_mean-test_std, test_mean+test_std, color='#DDDDDD')

plt.title("Learning Curve")
plt.xlabel("Training Size")
plt.ylabel("Accuracy Score")
plt.legend(loc='best')

"""**ROC ve AUC**"""

from yellowbrick.classifier import ROCAUC

fig, ax = plt.subplots(1,1,figsize=(12,8))
roc_auc = ROCAUC(clf, ax=ax)
roc_auc.fit(pc_train, y_train)
roc_auc.score(pc_test,y_test)

roc_auc.poof()